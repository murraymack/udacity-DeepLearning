## Chapter 2: Recurrent Neural Networks (RNNs)

### Lesson 1: Introduction to Recurrent Neural Networks
1. [Code - Generate a descriptive caption](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning)
2. [Widget - Sketch RNN Demo](https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html)
3. [Article - Vanishing Gradient](https://en.wikipedia.org/wiki/Vanishing_gradient_problem)
4. [Article - OpenAI: DotA 2 Bot](https://blog.openai.com/dota-2/)
5. [Video - Adding sounds to silent movies](https://www.youtube.com/watch?time_continue=1&v=0FW99AQmMc8)
6. [Widget - Handwriting Generation](http://www.cs.toronto.edu/~graves/handwriting.cgi?text=My+name+is+Luka&style=&bias=0.15&samples=3)
7. [Article - Amazon: Lex](https://aws.amazon.com/lex/faqs/)
8. [Article - Facebook: Building Language Models](https://code.facebook.com/posts/1827693967466780/building-an-efficient-neural-language-model-over-a-billion-words/)
9. [Paper - Netflix RNNs](https://arxiv.org/pdf/1511.06939.pdf)
10. [Article - Activation Functions](https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions)
11. [Article - cs231 Andrej Karpathy, ReLUs can die](https://cs231n.github.io/neural-networks-1/#nn)
12. [Article - Cross Entropy, Mathy](https://www.ics.uci.edu/~pjsadows/notes.pdf)
13. [Cheatsheet - Rules of Calculus](http://www.columbia.edu/itc/sipa/math/calc_rules_multivar.html)
14. [Cheatsheet - Common Derivatives](http://tutorial.math.lamar.edu/pdf/Common_Derivatives_Integrals.pdf)
15. [Article - Tuning Learning Rates in Gradient Descent](http://blog.datumbox.com/tuning-the-learning-rate-in-gradient-descent/)
16. [Article - 'Bold Driver' Gradient Descent Optimization](https://cnl.salk.edu/~schraudo/teach/NNcourse/momrate.html)
17. [Curriculum - cs231 Andrej Karpathy, Tuning Learning Rates](https://cs231n.github.io/neural-networks-3/#baby)
18. [Paper - Elman Network (Elman 1990)](https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog1402_1)
19. [Paper - Gradient Clipping (Bengio 2013)](https://arxiv.org/abs/1211.5063)
20. [Paper - LSTMs / Long Short-Term Memory (Hocreiter 1997)](http://www.bioinf.jku.at/publications/older/2604.pdf)

### Lesson 2: Long Short-Term Memory Networks
1. [Blog Post - Understanding LSTM Networks (Chris Olah)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
2. [Blog Post - Exploring LSTMs (Edwin Chen)](http://blog.echen.me/2017/05/30/exploring-lstms/)
3. [Video - cs231 Andrej Karpathy, RNNs, Image Captioning, LSTM](https://www.youtube.com/watch?v=iX5V1WpxxkY)
4. [Lecture - Gated Recurrent Units (Guerzhoy 2016)](http://www.cs.toronto.edu/~guerzhoy/321/lec/W09/rnn_gated.pdf)

### Lesson 3: Implementation of RNN & LSTM
1. [Code - Simple_RNN.pynb (Udacity)](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/recurrent-neural-networks/time-series/Simple_RNN.ipynb)
